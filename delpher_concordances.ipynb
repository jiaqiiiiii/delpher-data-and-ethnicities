{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9486ead1-0e36-4dfd-b033-b4e04a4d2cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5g/vgjq024s5fgc9pf2fchw5m6c0000gn/T/ipykernel_415/1358407541.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>context</th>\n",
       "      <th>year</th>\n",
       "      <th>file_path</th>\n",
       "      <th>original_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>waerts haer Bagagie nevens die van andere Perf...</td>\n",
       "      <td>1689</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>; wcrwaerts haer Bagagie nevens die van andere...</td>\n",
       "      <td>1689</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>de Jser op foo wjerdige Perlbnen , om'teenen't...</td>\n",
       "      <td>1683</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Inboorling,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>de Convocatie in deefe ftad fullen mogen wej f...</td>\n",
       "      <td>1696</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>doen.' Dc Belegerde waren 700 Soldarten fterek...</td>\n",
       "      <td>1685</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>moren</td>\n",
       "      <td>eg gekfleld , en aldaer gelukkig binnen gebrag...</td>\n",
       "      <td>1694</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>moren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>moren</td>\n",
       "      <td>na deßrander ter onder* vraging derOnder-Offic...</td>\n",
       "      <td>1693</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Moren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>moren</td>\n",
       "      <td>mt'chttiïtètGequeiflenquain bekennen 'iOtA&amp;Z e...</td>\n",
       "      <td>1692</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>mor&amp;en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>moren</td>\n",
       "      <td>b' eerste / dcwdcke dus weder crijdirert shnöc...</td>\n",
       "      <td>1645</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>moren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>moren</td>\n",
       "      <td>Antwerpen naer Cculen,Limburg aen deLaen,Franc...</td>\n",
       "      <td>1697</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Moren.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word                                            context  year  \\\n",
       "0    inboorling  waerts haer Bagagie nevens die van andere Perf...  1689   \n",
       "1    inboorling  ; wcrwaerts haer Bagagie nevens die van andere...  1689   \n",
       "2    inboorling  de Jser op foo wjerdige Perlbnen , om'teenen't...  1683   \n",
       "3    inboorling  de Convocatie in deefe ftad fullen mogen wej f...  1696   \n",
       "4    inboorling  doen.' Dc Belegerde waren 700 Soldarten fterek...  1685   \n",
       "..          ...                                                ...   ...   \n",
       "203       moren  eg gekfleld , en aldaer gelukkig binnen gebrag...  1694   \n",
       "204       moren  na deßrander ter onder* vraging derOnder-Offic...  1693   \n",
       "205       moren  mt'chttiïtètGequeiflenquain bekennen 'iOtA&Z e...  1692   \n",
       "206       moren  b' eerste / dcwdcke dus weder crijdirert shnöc...  1645   \n",
       "207       moren  Antwerpen naer Cculen,Limburg aen deLaen,Franc...  1697   \n",
       "\n",
       "                                             file_path original_token  \n",
       "0    /data/groups/trifecta/jiaqiz/downloaded_zip_de...     Inboorling  \n",
       "1    /data/groups/trifecta/jiaqiz/downloaded_zip_de...     Inboorling  \n",
       "2    /data/groups/trifecta/jiaqiz/downloaded_zip_de...    Inboorling,  \n",
       "3    /data/groups/trifecta/jiaqiz/downloaded_zip_de...     inboorling  \n",
       "4    /data/groups/trifecta/jiaqiz/downloaded_zip_de...     Inboorling  \n",
       "..                                                 ...            ...  \n",
       "203  /data/groups/trifecta/jiaqiz/downloaded_zip_de...          moren  \n",
       "204  /data/groups/trifecta/jiaqiz/downloaded_zip_de...          Moren  \n",
       "205  /data/groups/trifecta/jiaqiz/downloaded_zip_de...         mor&en  \n",
       "206  /data/groups/trifecta/jiaqiz/downloaded_zip_de...          moren  \n",
       "207  /data/groups/trifecta/jiaqiz/downloaded_zip_de...         Moren.  \n",
       "\n",
       "[208 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seventeenth_contexts = pd.read_csv('/Users/zhujiaqi/Downloads/1600_unique_contexts_by_word.csv')\n",
    "\n",
    "seventeenth_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d41a420-91f4-4ce8-90bd-20edf27c8d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>context</th>\n",
       "      <th>year</th>\n",
       "      <th>file_path</th>\n",
       "      <th>original_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>van Sici!ic« b' ponh-'ii , lchccn te willen ft...</td>\n",
       "      <td>1731</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>ITALIEN. NApels den 14 Augufti. De Vicerby gae...</td>\n",
       "      <td>1731</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>..eden ij July. Zondag-morgen pafleetde doot d...</td>\n",
       "      <td>1732</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>inboorling,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>koetfen met s paerden , te gemoet gezonden , e...</td>\n",
       "      <td>1732</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>in de Conftitutie behoorde te ftellen , dat he...</td>\n",
       "      <td>1736</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>inboorling,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>moren</td>\n",
       "      <td>genaamtd JtHaa» , byna nog nieuw, met.zvn Huyz...</td>\n",
       "      <td>1762</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Mor-en,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>moren</td>\n",
       "      <td>en folie Jolles Laurensz., Makelaars, zullen o...</td>\n",
       "      <td>1762</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>mor?en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>moren</td>\n",
       "      <td>als HC*OY LANDEN, gelegen zo buytenck Veenderv...</td>\n",
       "      <td>1762</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Moren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>moren</td>\n",
       "      <td>S al. Vn jtrmtmnfeM, vetko;pen agtfi.hoone Z a...</td>\n",
       "      <td>1762</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>mor?en«</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>moren</td>\n",
       "      <td>van Eigendom en VeiLCoi!«.iüitn zullen yier da...</td>\n",
       "      <td>1762</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Moren®</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word                                            context  year  \\\n",
       "0     inboorling  van Sici!ic« b' ponh-'ii , lchccn te willen ft...  1731   \n",
       "1     inboorling  ITALIEN. NApels den 14 Augufti. De Vicerby gae...  1731   \n",
       "2     inboorling  ..eden ij July. Zondag-morgen pafleetde doot d...  1732   \n",
       "3     inboorling  koetfen met s paerden , te gemoet gezonden , e...  1732   \n",
       "4     inboorling  in de Conftitutie behoorde te ftellen , dat he...  1736   \n",
       "...          ...                                                ...   ...   \n",
       "4213       moren  genaamtd JtHaa» , byna nog nieuw, met.zvn Huyz...  1762   \n",
       "4214       moren  en folie Jolles Laurensz., Makelaars, zullen o...  1762   \n",
       "4215       moren  als HC*OY LANDEN, gelegen zo buytenck Veenderv...  1762   \n",
       "4216       moren  S al. Vn jtrmtmnfeM, vetko;pen agtfi.hoone Z a...  1762   \n",
       "4217       moren  van Eigendom en VeiLCoi!«.iüitn zullen yier da...  1762   \n",
       "\n",
       "                                              file_path original_token  \n",
       "0     /data/groups/trifecta/jiaqiz/downloaded_zip_de...     Inboorling  \n",
       "1     /data/groups/trifecta/jiaqiz/downloaded_zip_de...     Inboorling  \n",
       "2     /data/groups/trifecta/jiaqiz/downloaded_zip_de...    inboorling,  \n",
       "3     /data/groups/trifecta/jiaqiz/downloaded_zip_de...     inboorling  \n",
       "4     /data/groups/trifecta/jiaqiz/downloaded_zip_de...    inboorling,  \n",
       "...                                                 ...            ...  \n",
       "4213  /data/groups/trifecta/jiaqiz/downloaded_zip_de...        Mor-en,  \n",
       "4214  /data/groups/trifecta/jiaqiz/downloaded_zip_de...         mor?en  \n",
       "4215  /data/groups/trifecta/jiaqiz/downloaded_zip_de...          Moren  \n",
       "4216  /data/groups/trifecta/jiaqiz/downloaded_zip_de...        mor?en«  \n",
       "4217  /data/groups/trifecta/jiaqiz/downloaded_zip_de...         Moren®  \n",
       "\n",
       "[4218 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eighteenth_contexts = pd.read_csv('/Users/zhujiaqi/Downloads/1700_unique_contexts_by_word.csv')\n",
    "\n",
    "eighteenth_contexts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad4136a-a70a-4dfd-9d27-fabdf7f586d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>context</th>\n",
       "      <th>year</th>\n",
       "      <th>file_path</th>\n",
       "      <th>original_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>geteelde koffie tegen ,en prijs dien het Gouve...</td>\n",
       "      <td>1879</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>fOOJÏ Geschiedenis f OOK l^i.^derWaldenzenl^»^...</td>\n",
       "      <td>1879</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>niet, anders zou die hem uit den mond van een ...</td>\n",
       "      <td>1879</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>der handeling betreft, boven het genoemde stuk...</td>\n",
       "      <td>1879</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inboorling</td>\n",
       "      <td>éea enkel sober maal per dag. Zou men nu ook n...</td>\n",
       "      <td>1879</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>inboorling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31162</th>\n",
       "      <td>moren</td>\n",
       "      <td>verwijderde zich J. de J., ko- Perslager alhie...</td>\n",
       "      <td>1854</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>mor-?en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31163</th>\n",
       "      <td>moren</td>\n",
       "      <td>van dit ongelukkig land, rijkelijk vergoed wor...</td>\n",
       "      <td>1854</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>«moren.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31164</th>\n",
       "      <td>moren</td>\n",
       "      <td>uitgeklaard Fossina Siers, K. S. Boiten. Rouaa...</td>\n",
       "      <td>1854</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>mor»en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31165</th>\n",
       "      <td>moren</td>\n",
       "      <td>Hollandsche Crushed zijn afgedaan 120 V. 110 t...</td>\n",
       "      <td>1854</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>Moren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31166</th>\n",
       "      <td>moren</td>\n",
       "      <td>par le R. P. Prat , de Ia Comp. de Jesus. 3 vo...</td>\n",
       "      <td>1854</td>\n",
       "      <td>/data/groups/trifecta/jiaqiz/downloaded_zip_de...</td>\n",
       "      <td>moren</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31167 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word                                            context  year  \\\n",
       "0      inboorling  geteelde koffie tegen ,en prijs dien het Gouve...  1879   \n",
       "1      inboorling  fOOJÏ Geschiedenis f OOK l^i.^derWaldenzenl^»^...  1879   \n",
       "2      inboorling  niet, anders zou die hem uit den mond van een ...  1879   \n",
       "3      inboorling  der handeling betreft, boven het genoemde stuk...  1879   \n",
       "4      inboorling  éea enkel sober maal per dag. Zou men nu ook n...  1879   \n",
       "...           ...                                                ...   ...   \n",
       "31162       moren  verwijderde zich J. de J., ko- Perslager alhie...  1854   \n",
       "31163       moren  van dit ongelukkig land, rijkelijk vergoed wor...  1854   \n",
       "31164       moren  uitgeklaard Fossina Siers, K. S. Boiten. Rouaa...  1854   \n",
       "31165       moren  Hollandsche Crushed zijn afgedaan 120 V. 110 t...  1854   \n",
       "31166       moren  par le R. P. Prat , de Ia Comp. de Jesus. 3 vo...  1854   \n",
       "\n",
       "                                               file_path original_token  \n",
       "0      /data/groups/trifecta/jiaqiz/downloaded_zip_de...     inboorling  \n",
       "1      /data/groups/trifecta/jiaqiz/downloaded_zip_de...     inboorling  \n",
       "2      /data/groups/trifecta/jiaqiz/downloaded_zip_de...     inboorling  \n",
       "3      /data/groups/trifecta/jiaqiz/downloaded_zip_de...     inboorling  \n",
       "4      /data/groups/trifecta/jiaqiz/downloaded_zip_de...     inboorling  \n",
       "...                                                  ...            ...  \n",
       "31162  /data/groups/trifecta/jiaqiz/downloaded_zip_de...        mor-?en  \n",
       "31163  /data/groups/trifecta/jiaqiz/downloaded_zip_de...        «moren.  \n",
       "31164  /data/groups/trifecta/jiaqiz/downloaded_zip_de...         mor»en  \n",
       "31165  /data/groups/trifecta/jiaqiz/downloaded_zip_de...          Moren  \n",
       "31166  /data/groups/trifecta/jiaqiz/downloaded_zip_de...          moren  \n",
       "\n",
       "[31167 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nineteenth_contexts = pd.read_csv('/Users/zhujiaqi/Downloads/1800_unique_contexts_by_word.csv')\n",
    "\n",
    "nineteenth_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14dac464-cf17-4209-b053-9a556bd1718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word frequency summary:\n",
      "  moor: 85 contexts\n",
      "  moren: 80 contexts\n",
      "  inboorling: 37 contexts\n",
      "  inboorlingen: 28 contexts\n",
      "Generating concordances...\n",
      "Processing concordances for: moor\n",
      "Found 76 concordance lines for 'moor'\n",
      "Processing concordances for: moren\n",
      "Found 79 concordance lines for 'moren'\n",
      "Processing concordances for: inboorling\n",
      "Found 9 concordance lines for 'inboorling'\n",
      "Processing concordances for: inboorlingen\n",
      "Found 28 concordance lines for 'inboorlingen'\n",
      "\n",
      "Concordance results saved to: /Users/zhujiaqi/Downloads/seventeenth_concordance_results.csv\n",
      "Total concordance lines: 192\n",
      "\n",
      "Summary by word:\n",
      "  moren: 79 lines\n",
      "  moor: 76 lines\n",
      "  inboorlingen: 28 lines\n",
      "  inboorling: 9 lines\n",
      "\n",
      "First 5 concordance results:\n",
      "   word  line_number                                     left_context keyword  \\\n",
      "0  moor            1  t 't schip de locge print , capit , gijsbert de    moor   \n",
      "1  moor            2   mift . ' b % lvrr , neaf # 4envar.hen ; ' ; de    moor   \n",
      "2  moor            3   het nieuwe oetroy opden 1 o september lactft ,    moor   \n",
      "3  moor            4  baftiaenmet de j-uüina.ca'piteyn paflcliie ? de    moor   \n",
      "4  moor            5  da jl fcheyete krieken beroof 1 , en vetfeheyde    moor   \n",
      "\n",
      "                                     right_context  \\\n",
      "0  , utet geüicke lsdinge '' j « kdea , ca gemonte   \n",
      "1   genomen. , » fooal , hy demoor mfende * nen-tn   \n",
      "2  hare hoog mog.de heercnsraten ccncracl at de ne   \n",
      "3  » lal van daer de poft op madrid « ernen .. ; ,   \n",
      "4  jen g jjej1 ! ! voorlede vvoerrfdaeh vettrock h   \n",
      "\n",
      "                                           full_line  \n",
      "0  t 't schip de locge print , capit , gijsbert d...  \n",
      "1  mift . ' b % lvrr , neaf # 4envar.hen ; ' ; de...  \n",
      "2  het nieuwe oetroy opden 1 o september lactft ,...  \n",
      "3  baftiaenmet de j-uüina.ca'piteyn paflcliie ? d...  \n",
      "4  da jl fcheyete krieken beroof 1 , en vetfeheyd...  \n",
      "\n",
      "==================================================\n",
      "Creating individual concordance files for each word...\n",
      "\n",
      "Processing individual concordance for: moor\n",
      "Saved 76 concordance lines for 'moor' to: /Users/zhujiaqi/Downloads/seventeenth_concordance_moor.csv\n",
      "\n",
      "Processing individual concordance for: moren\n",
      "Saved 79 concordance lines for 'moren' to: /Users/zhujiaqi/Downloads/seventeenth_concordance_moren.csv\n",
      "\n",
      "Processing individual concordance for: inboorling\n",
      "Saved 9 concordance lines for 'inboorling' to: /Users/zhujiaqi/Downloads/seventeenth_concordance_inboorling.csv\n",
      "\n",
      "Processing individual concordance for: inboorlingen\n",
      "Saved 28 concordance lines for 'inboorlingen' to: /Users/zhujiaqi/Downloads/seventeenth_concordance_inboorlingen.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "# Download required NLTK data if not already present\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Words to analyze\n",
    "target_words = ['moor', 'moren', 'inboorling', 'inboorlingen']\n",
    "\n",
    "def create_concordance_for_word(df, word, context_column='context'):\n",
    "    \"\"\"\n",
    "    Create concordance for a specific word from the dataframe\n",
    "    \"\"\"\n",
    "    # Filter rows that contain the target word (case insensitive)\n",
    "    word_rows = df[df[context_column].str.contains(word, case=False, na=False)]\n",
    "    \n",
    "    if len(word_rows) == 0:\n",
    "        print(f\"No instances of '{word}' found in the data\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Combine all contexts containing the word\n",
    "    all_text = ' '.join(word_rows[context_column].fillna('').astype(str))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(all_text.lower())\n",
    "    \n",
    "    # Create NLTK Text object\n",
    "    text = Text(tokens)\n",
    "    \n",
    "    # Capture concordance output\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    \n",
    "    # Generate concordance (default width is 79, lines is 25)\n",
    "    text.concordance(word.lower(), width=100, lines=1000)  # Increased width and lines\n",
    "    \n",
    "    # Restore stdout and get the output\n",
    "    sys.stdout = old_stdout\n",
    "    concordance_output = mystdout.getvalue()\n",
    "    \n",
    "    # Parse concordance output into structured data\n",
    "    concordance_lines = concordance_output.strip().split('\\n')\n",
    "    \n",
    "    # Remove header and empty lines\n",
    "    concordance_lines = [line for line in concordance_lines if line.strip() and not line.startswith('Displaying')]\n",
    "    \n",
    "    concordance_data = []\n",
    "    for i, line in enumerate(concordance_lines):\n",
    "        if line.strip():\n",
    "            # Split the line to extract left context, keyword, right context\n",
    "            # NLTK concordance format typically centers the keyword\n",
    "            parts = line.split()\n",
    "            if len(parts) > 0:\n",
    "                # Find the target word in the line (case insensitive)\n",
    "                line_lower = line.lower()\n",
    "                word_lower = word.lower()\n",
    "                \n",
    "                if word_lower in line_lower:\n",
    "                    # Find the position of the word\n",
    "                    word_start = line_lower.find(word_lower)\n",
    "                    word_end = word_start + len(word_lower)\n",
    "                    \n",
    "                    left_context = line[:word_start].strip()\n",
    "                    keyword = line[word_start:word_end]\n",
    "                    right_context = line[word_end:].strip()\n",
    "                    \n",
    "                    concordance_data.append({\n",
    "                        'word': word,\n",
    "                        'line_number': i + 1,\n",
    "                        'left_context': left_context,\n",
    "                        'keyword': keyword,\n",
    "                        'right_context': right_context,\n",
    "                        'full_line': line.strip()\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(concordance_data)\n",
    "\n",
    "def create_concordances_for_all_words(df, words):\n",
    "    \"\"\"\n",
    "    Create concordances for all specified words and combine results\n",
    "    \"\"\"\n",
    "    all_concordances = []\n",
    "    \n",
    "    for word in words:\n",
    "        print(f\"Processing concordances for: {word}\")\n",
    "        word_concordance = create_concordance_for_word(df, word)\n",
    "        if not word_concordance.empty:\n",
    "            all_concordances.append(word_concordance)\n",
    "            print(f\"Found {len(word_concordance)} concordance lines for '{word}'\")\n",
    "        else:\n",
    "            print(f\"No concordances found for '{word}'\")\n",
    "    \n",
    "    if all_concordances:\n",
    "        combined_concordances = pd.concat(all_concordances, ignore_index=True)\n",
    "        return combined_concordances\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Summary statistics\n",
    "word_counts = {}\n",
    "for word in target_words:\n",
    "    count = len(seventeenth_contexts[seventeenth_contexts['context'].str.contains(word, case=False, na=False)])\n",
    "    word_counts[word] = count\n",
    "\n",
    "print(f\"\\nWord frequency summary:\")\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"  {word}: {count} contexts\")\n",
    "\n",
    "# Generate concordances for all target words\n",
    "print(\"Generating concordances...\")\n",
    "concordance_results = create_concordances_for_all_words(seventeenth_contexts, target_words)\n",
    "\n",
    "# Save results to CSV\n",
    "if not concordance_results.empty:\n",
    "    output_file = '/Users/zhujiaqi/Downloads/seventeenth_concordance_results.csv'\n",
    "    concordance_results.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"\\nConcordance results saved to: {output_file}\")\n",
    "    print(f\"Total concordance lines: {len(concordance_results)}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nSummary by word:\")\n",
    "    word_counts = concordance_results['word'].value_counts()\n",
    "    for word, count in word_counts.items():\n",
    "        print(f\"  {word}: {count} lines\")\n",
    "    \n",
    "    # Display first few results\n",
    "    print(f\"\\nFirst 5 concordance results:\")\n",
    "    print(concordance_results.head())\n",
    "    \n",
    "else:\n",
    "    print(\"No concordance results found for any of the target words.\")\n",
    "\n",
    "# Alternative approach: Create individual concordance files for each word\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating individual concordance files for each word...\")\n",
    "\n",
    "for word in target_words:\n",
    "    print(f\"\\nProcessing individual concordance for: {word}\")\n",
    "    word_concordance = create_concordance_for_word(seventeenth_contexts, word)\n",
    "    \n",
    "    if not word_concordance.empty:\n",
    "        individual_file = f'/Users/zhujiaqi/Downloads/seventeenth_concordance_{word}.csv'\n",
    "        word_concordance.to_csv(individual_file, index=False, encoding='utf-8')\n",
    "        print(f\"Saved {len(word_concordance)} concordance lines for '{word}' to: {individual_file}\")\n",
    "    else:\n",
    "        print(f\"No concordance lines found for '{word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2d66db-bc97-417b-a03d-47bb2c3df34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word frequency summary:\n",
      "  moor: 2160 contexts\n",
      "  moren: 715 contexts\n",
      "  inboorling: 1067 contexts\n",
      "  inboorlingen: 846 contexts\n",
      "Generating concordances...\n",
      "Processing concordances for: moor\n",
      "Found 1000 concordance lines for 'moor'\n",
      "Processing concordances for: moren\n",
      "Found 743 concordance lines for 'moren'\n",
      "Processing concordances for: inboorling\n",
      "Found 228 concordance lines for 'inboorling'\n",
      "Processing concordances for: inboorlingen\n",
      "Found 867 concordance lines for 'inboorlingen'\n",
      "\n",
      "Concordance results saved to: /Users/zhujiaqi/Downloads/eighteenth_concordance_results.csv\n",
      "Total concordance lines: 2838\n",
      "\n",
      "Summary by word:\n",
      "  moor: 1000 lines\n",
      "  inboorlingen: 867 lines\n",
      "  moren: 743 lines\n",
      "  inboorling: 228 lines\n",
      "\n",
      "First 5 concordance results:\n",
      "   word  line_number                                     left_context keyword  \\\n",
      "0  moor            1  lers bel.end maken . de comier d : c wegens den    moor   \n",
      "1  moor            2  illürs beleend maken . de comier die wegens den    moor   \n",
      "2  moor            3  rerdam.george ougrerlony van venetien , robbert    moor   \n",
      "3  moor            4  en bieedc'cang tuflehen beyde , befloten meteen    moor   \n",
      "4  moor            5   had vin onzen koning tot prefent onrfingen een    moor   \n",
      "\n",
      "                                     right_context  \\\n",
      "0  van den martpis p-juavicini , na conft.iniiiiop   \n",
      "1  van den manpis p^llavicini , na vjonftjiitiuo .   \n",
      "2  van nnntes , anrhonio da colta ribeiro van stok   \n",
      "3  yzet hek ; ftaende ac roorl ' . huyzinge binnen   \n",
      "4   , van een cxuaordinaiie grootte en wclgcraaekt   \n",
      "\n",
      "                                           full_line  \n",
      "0  lers bel.end maken . de comier d : c wegens de...  \n",
      "1  illürs beleend maken . de comier die wegens de...  \n",
      "2  rerdam.george ougrerlony van venetien , robber...  \n",
      "3  en bieedc'cang tuflehen beyde , befloten metee...  \n",
      "4  had vin onzen koning tot prefent onrfingen een...  \n",
      "\n",
      "==================================================\n",
      "Creating individual concordance files for each word...\n",
      "\n",
      "Processing individual concordance for: moor\n",
      "Saved 1000 concordance lines for 'moor' to: /Users/zhujiaqi/Downloads/eighteenth_concordance_moor.csv\n",
      "\n",
      "Processing individual concordance for: moren\n",
      "Saved 743 concordance lines for 'moren' to: /Users/zhujiaqi/Downloads/eighteenth_concordance_moren.csv\n",
      "\n",
      "Processing individual concordance for: inboorling\n",
      "Saved 228 concordance lines for 'inboorling' to: /Users/zhujiaqi/Downloads/eighteenth_concordance_inboorling.csv\n",
      "\n",
      "Processing individual concordance for: inboorlingen\n",
      "Saved 867 concordance lines for 'inboorlingen' to: /Users/zhujiaqi/Downloads/eighteenth_concordance_inboorlingen.csv\n"
     ]
    }
   ],
   "source": [
    "# Words to analyze\n",
    "target_words = ['moor', 'moren', 'inboorling', 'inboorlingen']\n",
    "\n",
    "def create_concordance_for_word(df, word, context_column='context'):\n",
    "    \"\"\"\n",
    "    Create concordance for a specific word from the dataframe\n",
    "    \"\"\"\n",
    "    # Filter rows that contain the target word (case insensitive)\n",
    "    word_rows = df[df[context_column].str.contains(word, case=False, na=False)]\n",
    "    \n",
    "    if len(word_rows) == 0:\n",
    "        print(f\"No instances of '{word}' found in the data\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Combine all contexts containing the word\n",
    "    all_text = ' '.join(word_rows[context_column].fillna('').astype(str))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(all_text.lower())\n",
    "    \n",
    "    # Create NLTK Text object\n",
    "    text = Text(tokens)\n",
    "    \n",
    "    # Capture concordance output\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    \n",
    "    # Generate concordance (default width is 79, lines is 25)\n",
    "    text.concordance(word.lower(), width=100, lines=1000)  # Increased width and lines\n",
    "    \n",
    "    # Restore stdout and get the output\n",
    "    sys.stdout = old_stdout\n",
    "    concordance_output = mystdout.getvalue()\n",
    "    \n",
    "    # Parse concordance output into structured data\n",
    "    concordance_lines = concordance_output.strip().split('\\n')\n",
    "    \n",
    "    # Remove header and empty lines\n",
    "    concordance_lines = [line for line in concordance_lines if line.strip() and not line.startswith('Displaying')]\n",
    "    \n",
    "    concordance_data = []\n",
    "    for i, line in enumerate(concordance_lines):\n",
    "        if line.strip():\n",
    "            # Split the line to extract left context, keyword, right context\n",
    "            # NLTK concordance format typically centers the keyword\n",
    "            parts = line.split()\n",
    "            if len(parts) > 0:\n",
    "                # Find the target word in the line (case insensitive)\n",
    "                line_lower = line.lower()\n",
    "                word_lower = word.lower()\n",
    "                \n",
    "                if word_lower in line_lower:\n",
    "                    # Find the position of the word\n",
    "                    word_start = line_lower.find(word_lower)\n",
    "                    word_end = word_start + len(word_lower)\n",
    "                    \n",
    "                    left_context = line[:word_start].strip()\n",
    "                    keyword = line[word_start:word_end]\n",
    "                    right_context = line[word_end:].strip()\n",
    "                    \n",
    "                    concordance_data.append({\n",
    "                        'word': word,\n",
    "                        'line_number': i + 1,\n",
    "                        'left_context': left_context,\n",
    "                        'keyword': keyword,\n",
    "                        'right_context': right_context,\n",
    "                        'full_line': line.strip()\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(concordance_data)\n",
    "\n",
    "def create_concordances_for_all_words(df, words):\n",
    "    \"\"\"\n",
    "    Create concordances for all specified words and combine results\n",
    "    \"\"\"\n",
    "    all_concordances = []\n",
    "    \n",
    "    for word in words:\n",
    "        print(f\"Processing concordances for: {word}\")\n",
    "        word_concordance = create_concordance_for_word(df, word)\n",
    "        if not word_concordance.empty:\n",
    "            all_concordances.append(word_concordance)\n",
    "            print(f\"Found {len(word_concordance)} concordance lines for '{word}'\")\n",
    "        else:\n",
    "            print(f\"No concordances found for '{word}'\")\n",
    "    \n",
    "    if all_concordances:\n",
    "        combined_concordances = pd.concat(all_concordances, ignore_index=True)\n",
    "        return combined_concordances\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Summary statistics\n",
    "word_counts = {}\n",
    "for word in target_words:\n",
    "    count = len(eighteenth_contexts[eighteenth_contexts['context'].str.contains(word, case=False, na=False)])\n",
    "    word_counts[word] = count\n",
    "\n",
    "print(f\"\\nWord frequency summary:\")\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"  {word}: {count} contexts\")\n",
    "\n",
    "# Generate concordances for all target words\n",
    "print(\"Generating concordances...\")\n",
    "concordance_results = create_concordances_for_all_words(eighteenth_contexts, target_words)\n",
    "\n",
    "# Save results to CSV\n",
    "if not concordance_results.empty:\n",
    "    output_file = '/Users/zhujiaqi/Downloads/eighteenth_concordance_results.csv'\n",
    "    concordance_results.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"\\nConcordance results saved to: {output_file}\")\n",
    "    print(f\"Total concordance lines: {len(concordance_results)}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nSummary by word:\")\n",
    "    word_counts = concordance_results['word'].value_counts()\n",
    "    for word, count in word_counts.items():\n",
    "        print(f\"  {word}: {count} lines\")\n",
    "    \n",
    "    # Display first few results\n",
    "    print(f\"\\nFirst 5 concordance results:\")\n",
    "    print(concordance_results.head())\n",
    "    \n",
    "else:\n",
    "    print(\"No concordance results found for any of the target words.\")\n",
    "\n",
    "# Alternative approach: Create individual concordance files for each word\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating individual concordance files for each word...\")\n",
    "\n",
    "for word in target_words:\n",
    "    print(f\"\\nProcessing individual concordance for: {word}\")\n",
    "    word_concordance = create_concordance_for_word(eighteenth_contexts, word)\n",
    "    \n",
    "    if not word_concordance.empty:\n",
    "        individual_file = f'/Users/zhujiaqi/Downloads/eighteenth_concordance_{word}.csv'\n",
    "        word_concordance.to_csv(individual_file, index=False, encoding='utf-8')\n",
    "        print(f\"Saved {len(word_concordance)} concordance lines for '{word}' to: {individual_file}\")\n",
    "    else:\n",
    "        print(f\"No concordance lines found for '{word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa6a345f-886f-4f50-a398-cbc81f2eb331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word frequency summary:\n",
      "  moor: 12462 contexts\n",
      "  moren: 1375 contexts\n",
      "  inboorling: 17404 contexts\n",
      "  inboorlingen: 15036 contexts\n",
      "Generating concordances...\n",
      "Processing concordances for: moor\n",
      "Found 1000 concordance lines for 'moor'\n",
      "Processing concordances for: moren\n",
      "Found 1000 concordance lines for 'moren'\n",
      "Processing concordances for: inboorling\n",
      "Found 1000 concordance lines for 'inboorling'\n",
      "Processing concordances for: inboorlingen\n",
      "Found 1000 concordance lines for 'inboorlingen'\n",
      "\n",
      "Concordance results saved to: /Users/zhujiaqi/Downloads/nineteenth_concordance_results.csv\n",
      "Total concordance lines: 4000\n",
      "\n",
      "Summary by word:\n",
      "  moor: 1000 lines\n",
      "  moren: 1000 lines\n",
      "  inboorling: 1000 lines\n",
      "  inboorlingen: 1000 lines\n",
      "\n",
      "First 5 concordance results:\n",
      "   word  line_number                                     left_context keyword  \\\n",
      "0  moor            1  staat is voor altijd daarvan uitgesloten ; geen    moor   \n",
      "1  moor            2  staal is voor altijd daarvan uitgesloten ; geen    moor   \n",
      "2  moor            3  n sprake was , nabij het eiland angua , genomen    moor   \n",
      "3  moor            4  n sprake was , nabij het eiland angua , genomen    moor   \n",
      "4  moor            5  t-zij inboorling of vreemdeling . dre . heer de    moor   \n",
      "\n",
      "                                     right_context  \\\n",
      "0   , arabier of jood wordt er in toegelaten . ook   \n",
      "1   , arabier of jood wordt er in toegelaten . 0 ,   \n",
      "2  de inboorlingen is er niets 11 i teer van de ko   \n",
      "3  de inboorlingen van solomon , was gezien en men   \n",
      "4  tastic ' het gevoelen van den heer dotrengc aan   \n",
      "\n",
      "                                           full_line  \n",
      "0  staat is voor altijd daarvan uitgesloten ; gee...  \n",
      "1  staal is voor altijd daarvan uitgesloten ; gee...  \n",
      "2  n sprake was , nabij het eiland angua , genome...  \n",
      "3  n sprake was , nabij het eiland angua , genome...  \n",
      "4  t-zij inboorling of vreemdeling . dre . heer d...  \n",
      "\n",
      "==================================================\n",
      "Creating individual concordance files for each word...\n",
      "\n",
      "Processing individual concordance for: moor\n",
      "Saved 1000 concordance lines for 'moor' to: /Users/zhujiaqi/Downloads/nineteenth_concordance_moor.csv\n",
      "\n",
      "Processing individual concordance for: moren\n",
      "Saved 1000 concordance lines for 'moren' to: /Users/zhujiaqi/Downloads/nineteenth_concordance_moren.csv\n",
      "\n",
      "Processing individual concordance for: inboorling\n",
      "Saved 1000 concordance lines for 'inboorling' to: /Users/zhujiaqi/Downloads/nineteenth_concordance_inboorling.csv\n",
      "\n",
      "Processing individual concordance for: inboorlingen\n",
      "Saved 1000 concordance lines for 'inboorlingen' to: /Users/zhujiaqi/Downloads/nineteenth_concordance_inboorlingen.csv\n"
     ]
    }
   ],
   "source": [
    "# Words to analyze\n",
    "target_words = ['moor', 'moren', 'inboorling', 'inboorlingen']\n",
    "\n",
    "def create_concordance_for_word(df, word, context_column='context'):\n",
    "    \"\"\"\n",
    "    Create concordance for a specific word from the dataframe\n",
    "    \"\"\"\n",
    "    # Filter rows that contain the target word (case insensitive)\n",
    "    word_rows = df[df[context_column].str.contains(word, case=False, na=False)]\n",
    "    \n",
    "    if len(word_rows) == 0:\n",
    "        print(f\"No instances of '{word}' found in the data\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Combine all contexts containing the word\n",
    "    all_text = ' '.join(word_rows[context_column].fillna('').astype(str))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(all_text.lower())\n",
    "    \n",
    "    # Create NLTK Text object\n",
    "    text = Text(tokens)\n",
    "    \n",
    "    # Capture concordance output\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    \n",
    "    # Generate concordance (default width is 79, lines is 25)\n",
    "    text.concordance(word.lower(), width=100, lines=1000)  # Increased width and lines\n",
    "    \n",
    "    # Restore stdout and get the output\n",
    "    sys.stdout = old_stdout\n",
    "    concordance_output = mystdout.getvalue()\n",
    "    \n",
    "    # Parse concordance output into structured data\n",
    "    concordance_lines = concordance_output.strip().split('\\n')\n",
    "    \n",
    "    # Remove header and empty lines\n",
    "    concordance_lines = [line for line in concordance_lines if line.strip() and not line.startswith('Displaying')]\n",
    "    \n",
    "    concordance_data = []\n",
    "    for i, line in enumerate(concordance_lines):\n",
    "        if line.strip():\n",
    "            # Split the line to extract left context, keyword, right context\n",
    "            # NLTK concordance format typically centers the keyword\n",
    "            parts = line.split()\n",
    "            if len(parts) > 0:\n",
    "                # Find the target word in the line (case insensitive)\n",
    "                line_lower = line.lower()\n",
    "                word_lower = word.lower()\n",
    "                \n",
    "                if word_lower in line_lower:\n",
    "                    # Find the position of the word\n",
    "                    word_start = line_lower.find(word_lower)\n",
    "                    word_end = word_start + len(word_lower)\n",
    "                    \n",
    "                    left_context = line[:word_start].strip()\n",
    "                    keyword = line[word_start:word_end]\n",
    "                    right_context = line[word_end:].strip()\n",
    "                    \n",
    "                    concordance_data.append({\n",
    "                        'word': word,\n",
    "                        'line_number': i + 1,\n",
    "                        'left_context': left_context,\n",
    "                        'keyword': keyword,\n",
    "                        'right_context': right_context,\n",
    "                        'full_line': line.strip()\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(concordance_data)\n",
    "\n",
    "def create_concordances_for_all_words(df, words):\n",
    "    \"\"\"\n",
    "    Create concordances for all specified words and combine results\n",
    "    \"\"\"\n",
    "    all_concordances = []\n",
    "    \n",
    "    for word in words:\n",
    "        print(f\"Processing concordances for: {word}\")\n",
    "        word_concordance = create_concordance_for_word(df, word)\n",
    "        if not word_concordance.empty:\n",
    "            all_concordances.append(word_concordance)\n",
    "            print(f\"Found {len(word_concordance)} concordance lines for '{word}'\")\n",
    "        else:\n",
    "            print(f\"No concordances found for '{word}'\")\n",
    "    \n",
    "    if all_concordances:\n",
    "        combined_concordances = pd.concat(all_concordances, ignore_index=True)\n",
    "        return combined_concordances\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Summary statistics\n",
    "word_counts = {}\n",
    "for word in target_words:\n",
    "    count = len(nineteenth_contexts[nineteenth_contexts['context'].str.contains(word, case=False, na=False)])\n",
    "    word_counts[word] = count\n",
    "\n",
    "print(f\"\\nWord frequency summary:\")\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"  {word}: {count} contexts\")\n",
    "\n",
    "# Generate concordances for all target words\n",
    "print(\"Generating concordances...\")\n",
    "concordance_results = create_concordances_for_all_words(nineteenth_contexts, target_words)\n",
    "\n",
    "# Save results to CSV\n",
    "if not concordance_results.empty:\n",
    "    output_file = '/Users/zhujiaqi/Downloads/nineteenth_concordance_results.csv'\n",
    "    concordance_results.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"\\nConcordance results saved to: {output_file}\")\n",
    "    print(f\"Total concordance lines: {len(concordance_results)}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nSummary by word:\")\n",
    "    word_counts = concordance_results['word'].value_counts()\n",
    "    for word, count in word_counts.items():\n",
    "        print(f\"  {word}: {count} lines\")\n",
    "    \n",
    "    # Display first few results\n",
    "    print(f\"\\nFirst 5 concordance results:\")\n",
    "    print(concordance_results.head())\n",
    "    \n",
    "else:\n",
    "    print(\"No concordance results found for any of the target words.\")\n",
    "\n",
    "# Alternative approach: Create individual concordance files for each word\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating individual concordance files for each word...\")\n",
    "\n",
    "for word in target_words:\n",
    "    print(f\"\\nProcessing individual concordance for: {word}\")\n",
    "    word_concordance = create_concordance_for_word(nineteenth_contexts, word)\n",
    "    \n",
    "    if not word_concordance.empty:\n",
    "        individual_file = f'/Users/zhujiaqi/Downloads/nineteenth_concordance_{word}.csv'\n",
    "        word_concordance.to_csv(individual_file, index=False, encoding='utf-8')\n",
    "        print(f\"Saved {len(word_concordance)} concordance lines for '{word}' to: {individual_file}\")\n",
    "    else:\n",
    "        print(f\"No concordance lines found for '{word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832ce4f-1daf-4973-b85a-25d4f8ca9bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
